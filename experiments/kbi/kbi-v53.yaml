
model:
  class_path: pytorch_gleam.modeling.models.KbiLanguageModel
  init_args:
    ke:
      class_path: pytorch_gleam.modeling.knowledge_embedding.TransMSEmbedding
      init_args:
        emb_size: 8
        hidden_size: 32
        gamma: 1.5
        loss_norm: 1
    threshold:
      class_path: pytorch_gleam.modeling.thresholds.MultiClassCallableThresholdModule
    metric:
      class_path: pytorch_gleam.modeling.metrics.F1PRMultiClassMetric
      init_args:
        mode: macro
        num_classes: 3
  learning_rate: 5e-5
  pre_model_name: digitalepidemiologylab/covid-twitter-bert-v2
  load_pre_model: true
trainer:
  deterministic: true
  check_val_every_n_epoch: 4
  max_epochs: 48
  accumulate_grad_batches: 8
data:
  batch_size: 4
  pos_samples: 1
  neg_samples: 1
  max_seq_len: 96
  tokenizer_name: digitalepidemiologylab/covid-twitter-bert-v2
  num_workers: 8
