
model:
  class_path: pytorch_gleam.modeling.models.KbiLanguageModel
  init_args:
    learning_rate: 5e-5
    pre_model_name: digitalepidemiologylab/covid-twitter-bert-v2
    load_pre_model: true
    ke:
      class_path: pytorch_gleam.modeling.knowledge_embedding.TransMSEmbedding
      init_args:
        emb_size: 8
        hidden_size: 32
        gamma: 1.5
        loss_norm: 1
    threshold:
      class_path: pytorch_gleam.modeling.thresholds.MultiClassCallableThresholdModule
      init_args:
        num_thresholds: 1
    metric:
      class_path: pytorch_gleam.modeling.metrics.F1PRMultiClassMetric
      init_args:
        mode: macro
        num_classes: 3
trainer:
  deterministic: true
  check_val_every_n_epoch: 4
  max_epochs: 48
  accumulate_grad_batches: 8
data:
  class_path: pytorch_gleam.data.datasets.KbiMisinfoStanceDataModule
  init_args:
    batch_size: 4
    pos_samples: 1
    neg_samples: 1
    max_seq_len: 96
    tokenizer_name: digitalepidemiologylab/covid-twitter-bert-v2
    num_workers: 8
