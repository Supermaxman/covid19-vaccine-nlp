seed_everything: 0
model:
  class_path: pytorch_gleam.modeling.models.NliTextLanguageModel
  init_args:
    learning_rate: 5e-5
    pre_model_name: digitalepidemiologylab/covid-twitter-bert-v2
    load_pre_model: true
    num_val_seeds: 1
    infer:
      class_path: pytorch_gleam.inference.MultiHopConsistencyScoring
      init_args:
        num_steps: 0
        num_classes: 3
    threshold:
      class_path: pytorch_gleam.modeling.thresholds.MultiClassMultiLabelThresholdModule
    metric:
      class_path: pytorch_gleam.modeling.metrics.F1PRMultiClassMetric
      init_args:
        mode: macro
        num_classes: 3
    m_metric:
      class_path: pytorch_gleam.modeling.metrics.F1PRMultiClassMetric
      init_args:
        mode: micro
        num_classes: 3
trainer:
  max_epochs: 10
  accumulate_grad_batches: 2
  check_val_every_n_epoch: 1
  deterministic: true
  num_sanity_val_steps: 0
  callbacks:
    - class_path: pytorch_gleam.callbacks.FitCheckpointCallback
    - class_path: pytorch_gleam.callbacks.JsonlWriter
data:
  class_path: pytorch_gleam.data.datasets.NliTextMisinfoStanceDataModule
  init_args:
    batch_size: 4
    max_seq_len: 256
    tokenizer_name: digitalepidemiologylab/covid-twitter-bert-v2
    num_workers: 8
    train_path: data/train.jsonl
    train_misinfo_path: data/misinfo.json
    val_path: data/dev.jsonl
    val_misinfo_path: data/misinfo.json
    test_path: data/test.jsonl
    test_misinfo_path: data/misinfo.json
    predict_path: data/test.jsonl
    predict_misinfo_path: data/misinfo.json
